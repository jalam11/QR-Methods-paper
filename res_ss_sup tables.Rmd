---
title: "res_ss_sup tables"
author: "Josh Alampi"
date: '2022-03-02'
output: html_document
---

#load
```{r}
#clear workspace
rm(list=ls(all=TRUE))

#load packages
library(readr); library(writexl) # for read_csv(); write_xlsx()
library(plyr) # mapvalues()
library(MASS)
library(dplyr)
library(tidyr) # for gather()
library(ggplot2)
library(ggrepel); library(ggpubr); library(scales) # extra ggplot features
library(signs) # for signs_format(), uses proper minus sign instead of hyphen
library(lmtest) # for bptest()
library(quantreg)
library(bayesQR)
select <- dplyr::select
library(rstan)
library(tidyverse)
source("functions/ggplot functions.R")
```

```{r}
data_dith <- read.csv("sim study/raw results/table_ss_JA model_2021-08-07_1000_sims.csv")
data_cnts <- read.csv("sim study/raw results/table_ss_JA moel_gold_2021-10-28_1000_sims.csv")

nrow(data_dith)
nrow(data_cnts)
```

# clean

## Count data
```{r}
data_dith <- data_dith %>% 
  filter(method != "bayes_adj_v1") # do not need adj_v1 (the default SW adjustment), as I have demonstrated earlier that it is defective. 

data_dith$method <- data_dith$method %>% # shorten the Bayesian methods' names
  mapvalues("bayes_adj_v2", "bnid") %>% 
  mapvalues("bayes", "biid") 

data_dith <- data_dith %>% # new variable: status tells us the type of data
  mutate(status = ifelse(method %in% c("bnid", "biid"),
                         "Bayesian", # Bayesian methods were not dithered
                         "Freq. (count)")) # Frequentist methods were dithered

```

## Continuous data (Bayesian methods not used)
```{r}
data_cnts <- data_cnts %>% 
  filter(is.na(method) == F) %>% # gets rid of blank method rows
  mutate(status = "Freq. (cnts)")

```

## combine
```{r}
data <- rbind(data_dith, data_cnts); nrow(data)
rm(data_dith, data_cnts)
```


# prep for analysis
## basic cleanup
```{r}
data$model <- data$model %>% # give the models proper names
  mapvalues(1, "Model 1") %>% 
  mapvalues(2, "Model 2") %>% 
  mapvalues(3, "Model 3") %>% 
  mapvalues(4, "Model 4") 

data$beta <- as.numeric(data$beta)
data$lb <- as.numeric(data$lb)
data$ub <- as.numeric(data$ub)
data$tau <- as.factor(data$tau)
```

## find interval width, remove infinite intervals
```{r}
# find interval width, with infinite intervals set to NA
data <- data %>% 
  mutate(int_width = ub - lb)

# Flag and delete infinite intervals
# Flag and delete simulations with no effect estimate
data <- data %>% 
  mutate(infin_flag = ifelse(is.infinite(lb) == T | is.infinite(ub) == T
                             # | lb > abs(10000) | ub > abs(10000)
                             ,
                             T, # interval is infinite or so large it should be removed
                             F) ) %>%
  mutate(na_flag = ifelse(is.na(beta) == T,
                          T, # no effect estimate is given due to failure to converge
                          F)) %>% 
  mutate(lb = ifelse(infin_flag == T | na_flag == T, NA, lb)) %>%
  mutate(ub = ifelse(infin_flag == T | na_flag == T, NA, ub)) %>%
  mutate(int_width = ifelse(infin_flag == T | na_flag == T, NA, int_width))

```

## find average beta and average CI width across each group of variable
```{r}
# Find the mean \hat(beta_i) across repetitions 
# Morris et al 2017 calls this value "beta-vinculum", the beta symboll with a flat line on top
data_summarised_1 <- data %>% 
  group_by(method, tau, model, n, status) %>% 
  summarise(mean_beta = mean(beta, na.rm = T)) 

# Repeat this process with mean(\hat(interval width))
data_summarised_2 <- data %>% 
  group_by(method, tau, model, n, status) %>% 
  summarise(mean_intwidth = mean(int_width, na.rm = T))


# Add this value to the dataframe
data <- merge(data, data_summarised_1, by=c("method", "tau", "model", "n", "status"))
data <- merge(data, data_summarised_2, by=c("method", "tau", "model", "n", "status"))
rm(data_summarised_1, data_summarised_2)
```

## Calculate performance measures 
```{r}
data1 <- data %>%
  mutate(n = paste0(("n = "), n)) %>% 
  
  # Performance measures
  mutate(hit_flag = ifelse(lb <= true_beta & ub >= true_beta,
                           T, #90% interval contains true_beta
                           F)) %>%
  
  mutate(hit_flag_be = ifelse(lb <= mean_beta & ub >= mean_beta,
                              T, #90% interval contains true_beta
                              F)) %>%
  
  mutate(bias = beta - true_beta) %>% 
  mutate(bias_rel = beta - mean_beta) %>%
  mutate(intwidth_rel = int_width - mean_intwidth) %>% 
  
  # Cleaning
  mutate(degen_flag = ifelse(beta == lb | beta == ub, # flag rows where beta = lb or ub
                             T, # interval is degenerate
                             F) ) %>%
  # New labels for methods
  mutate(group = ifelse(method %in% c("biid", "bnid"), 
                      "Bayesian",
                      ifelse(method %in% c("iid", "ker", "nid"), 
                             "Direct Estimation",
                             ifelse(method %in% c("riid", "rnid"),
                                    "Rank-Based",
                                    "Bootstrap"))))


# force methods to be read in a particular order
data1$method <- factor(data1$method, levels = c("iid", "nid", "ker", "riid", "rnid", 
                                            "xy", "wxy", "pwy", "mcmb", "wild", "pbs", 
                                            "biid", "bnid"))
```

Testing
```{r}
# OLD: used for testing intwidth_var
data_variability <- data %>% 
  mutate(n = paste0(("n = "), n)) %>% 
  mutate(intwidth_rel = int_width - mean_intwidth) %>% 
  filter(is.na(intwidth_rel) == F) %>% 
  mutate(infin_flag = ifelse(is.infinite(lb) == T | is.infinite(ub) == T, # flag rows w infinite intervals
                             T, # interval is degenerate
                             F) )



data_mcmb_notconverged <- data1 %>% 
  filter(method == "mcmb") %>% 
  # filter(is.na(beta) == T) %>% 
  filter(model == "Model 3")
```


## make "res" (shortens "data" into something which can actually be interpretted)
```{r}
sims <- 1000 # the number of simulations that were run. Use this for bias, empSE, and MSE
# "nsims" variable will be created to determine the number of simulations which gave non-infinite intervals. 

# Calculations for these performance measures came from Morris et al. 2017!

res <- data1 %>% 
  group_by(method, n, model, tau, group, status) %>% 
  summarise(degen = sum(degen_flag == T) / sims, # proportion of degenerate intervals
            infin = sum(infin_flag == T) / sims, # proportion of infinite intervals
            na = sum(na_flag == T) / sims, # proportion of effect estimates failing to converge
            skip = (sum(infin_flag == T | na_flag == T) / sims), # proportion of skips needed
            nsims = sims - (sims*skip), # the number of simulations with no problems
            
            # effect estimate-based performance measures
            ## Note: will only use riid, biid method for this, so I do NOT need to take infinite intervals or effect estimates that failed to converge into account (as this was only a problem for the mcmb method). Thus I use "sims" and not "nsims". 
            bias = sum(bias) / sims,
            bias_se = sqrt( sum((bias_rel)^2) / (sims * (sims -1)) ),
            
            empSE = sqrt( sum((bias_rel)^2) / (sims - 1) ),
            empSE_se = empSE / sqrt( 2  * (sims - 1) ), # empSE_se depends on empSE value
            
            MSE = sum((bias)^2) / sims,
            MSE_se = sqrt( ( sum( (bias)^2 - MSE) )^2 / sims*(sims-1) ), # MSE_se depends on MSE value
            
            
            # interval-based performance measures
            cov = sum(hit_flag == T, na.rm = T) / nsims, #### Emperical coverage probability
            cov_se = sqrt( cov * (1-cov) / nsims ), # cov_se depends on cov value
            
            cov_be = sum(hit_flag_be == T, na.rm = T) / nsims, #### Bias-adjusted Emperical Coverage Prob.
            cov_be_se = sqrt( cov_be * (1-cov_be) / nsims ), # cov_be_se depends on cov_be value
            
            intwidth_sd = sd(int_width, na.rm = T),
            
            intwidth_empSE = sqrt( sum((intwidth_rel)^2, na.rm = T) / (nsims - 1) ),
            intwidth_empSE_se = intwidth_empSE / sqrt( 2  * (nsims - 1) ), 
            
            meanbeta = mean(beta)
            ) 


res$method <- factor(res$method, levels = c("iid", "nid", "ker", "riid", "rnid", 
                                            "xy", "wxy", "pwy", "mcmb", "wild", "pbs", 
                                            "biid", "bnid"))

res <- res %>% 
  mutate(blank = F)
# res$blank <- as.factor(res$blank)



# Note: MSE, MSE_se, cov_be, cov_be_se, intwidth_sd, meanbeta are no longer used in the analysis. Left them in anyways in case I end up needing them at some point. 
```

testing
```{r}
# res_variability <- data_variability %>% 
#   group_by(method, n, model, tau, group, dithered, gold) %>% 
#   summarise(infin = sum(infin_flag == T) / sims, # frequency of infinite intervals
#            nsims = sims - (sims*infin), # the number of simulations with non-infinite intervals
#             
#            intwidth_empSE = sqrt( sum((intwidth_rel)^2, na.rm = T) / (nsims - 1) ),
#            intwidth_empSE_se = intwidth_empSE / sqrt( 2  * (nsims - 1) )
#            )

testing_res_na <- res %>% 
  filter(na != 0)

testing_res_infin <- res %>% 
  filter(infin != 0)

testing_res_degen <- res %>% 
  filter(degen != 0)

testing_res_skip <- res %>% 
  filter(skip != 0)
```


## filter "res"
```{r}
# dataset for bias and empSE
## all 11 frequentist methods give the same beta estimate.
## both Bayesian methods give the same beta estimate
res_short <- res %>% 
  filter(method %in% c("riid", "biid")) %>% 
  mutate(group_reformat = ifelse(group != "Bayesian", # Change the lables for the "group" variable
                           "Frequentist
(iid, nid, 
ker, riid, 
rnid, xy, wxy, 
pwy, mcmb, 
wild, pbs)",
                           "Bayesian
(biid, bnid)")) 


# datasets for empirical coverage prob and CI width_var

res_count <- res %>% ## Uses all 13 methods, Only count data is simulated
  filter(status != "Freq. (cnts)")

res_cnts <- res %>% ## Uses all 11 Frequentist methods (Bayesian methods ommitted), only countinuous data is simulated
  filter(status == "Freq. (cnts)")

res_count_vs_cnts <- res %>% # For comparing dith. FQR on count data vs undithered FQR on continuous data
  filter(status != "Bayesian")

```

## quick fix

```{r}
res_count_vs_cnts$status <- res_count_vs_cnts$status %>% 
  mapvalues("Freq. (cnts)", "cnts") %>% 
  mapvalues("Freq. (count)", "count") 
```

# Make tables

## Coverage

### Count data only
```{r}
r_1 <- 2
r_2 <- 3

table_cov <- res_count %>% 
  mutate(n = str_sub(n, 5, 7)) %>% 
  mutate(model = str_sub(model, 7, 7)) %>% 
  
  select(c(n, model, method, tau, cov, cov_se)) %>% 
  group_by(n, model, method, tau) %>% 
  pivot_wider(names_from = tau, values_from = c(cov, cov_se)) %>% 
  arrange(n, model) %>% 
  mutate(cov_10 = paste0(as.character(round(cov_0.1, r_1)),
                         " (",
                         round(cov_se_0.1, r_2),
                        ")") ) %>% 
  mutate(cov_30 = paste0(round(cov_0.3, r_1),
                         " (",
                         round(cov_se_0.3, r_2),
                        ")") ) %>% 
  mutate(cov_50 = paste0(round(cov_0.5, r_1),
                         " (",
                         round(cov_se_0.5, r_2),
                        ")") ) %>% 
  mutate(cov_70 = paste0(round(cov_0.7, r_1),
                         " (",
                         round(cov_se_0.7, r_2),
                        ")") ) %>% 
  mutate(cov_90 = paste0(round(cov_0.9, r_1),
                         " (",
                         round(cov_se_0.9, r_2),
                        ")") ) %>% 
  select(-c(cov_0.1:cov_se_0.9)) %>% 
  select(-c(group))

```
### Count vs cnts
```{r}


table_cov_cvsc <- res_count_vs_cnts %>% 
  mutate(n = str_sub(n, 5, 7)) %>% 
  mutate(model = str_sub(model, 7, 7)) %>% 
  
  select(c(n, model, method, tau, status, cov, cov_se)) %>% 
  group_by(n, model, method, tau, status) %>% 
  pivot_wider(names_from = status, values_from = c(cov, cov_se)) %>% 
  arrange(n, model) %>% 
  mutate(count = paste0(as.character(round(cov_count, r_1)),
                         " (",
                         round(cov_se_count, r_2),
                        ")") ) %>% 
  mutate(cnts = paste0(round(cov_cnts, r_1),
                         " (",
                         round(cov_se_cnts, r_2),
                        ")") ) %>% 
  select(-c(cov_cnts:cov_se_count)) %>% 
  select(-c(group))

```


## intwidth var

### count data only
```{r}
r_1 <- 2
r_2 <- 3

table_intwidthvar <- res_count %>% 
  filter(tau == 0.9) %>% 
  mutate(n = str_sub(n, 5, 7)) %>% 
  mutate(model = str_sub(model, 7, 7))%>% 
  
  select(c(n, model, method, intwidth_empSE, intwidth_empSE_se))%>% 
  group_by(n, model, method) %>% 
  pivot_wider(names_from = model, values_from = c(intwidth_empSE, intwidth_empSE_se))%>% 
  arrange(n) %>% 
  mutate(mod1 = paste0(as.character(round(intwidth_empSE_1, r_1)),
                         " (",
                         round(intwidth_empSE_se_1, r_2),
                        ")") ) %>% 
  mutate(mod2 = paste0(as.character(round(intwidth_empSE_2, r_1)),
                         " (",
                         round(intwidth_empSE_se_2, r_2),
                        ")") ) %>% 
  mutate(mod3 = paste0(as.character(round(intwidth_empSE_3, r_1)),
                         " (",
                         round(intwidth_empSE_se_3, r_2),
                        ")") ) %>% 
  mutate(mod4 = paste0(as.character(round(intwidth_empSE_4, r_1)),
                         " (",
                         round(intwidth_empSE_se_4, r_2),
                        ")") ) %>% 
  select(-c(intwidth_empSE_1:intwidth_empSE_se_4)) %>% 
  select(-c(group, tau))


```
### count vs cnts
```{r}
r_1 <- 2
r_2 <- 3

table_iw_cvsc <- res_count_vs_cnts %>% 
  filter(tau == 0.9) %>% 
  mutate(n = str_sub(n, 5, 7)) %>% 
  mutate(model = str_sub(model, 7, 7))%>% 
  
  select(c(n, model, method, status, intwidth_empSE, intwidth_empSE_se))%>% 
  group_by(n, model, method) %>% 
  pivot_wider(names_from = status, values_from = c(intwidth_empSE, intwidth_empSE_se)) %>% 
  arrange(n) %>% 
  mutate(count = paste0(as.character(round(intwidth_empSE_count, r_1)),
                         " (",
                         round(intwidth_empSE_se_count, r_2),
                        ")") ) %>% 
  mutate(cnts = paste0(round(intwidth_empSE_cnts, r_1),
                         " (",
                         round(intwidth_empSE_se_cnts, r_2),
                       ")") ) %>% 
  select(-c(intwidth_empSE_cnts:intwidth_empSE_se_count)) %>% 
  select(-c(group, tau))
  
  
```

```{r}
library(openxlsx)

dataset_names <- list('Excel Table S1' = table_cov, 'Excel Table S2' = table_intwidthvar, 
                      'Excel Table S3' = table_cov_cvsc, "Excel Table S4" = table_iw_cvsc)


openxlsx::write.xlsx(dataset_names, file = 'Supplementary Excel File.xlsx') 
```



```{r}

```

















